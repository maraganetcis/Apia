# core_engine/apia_core.py
import os
import json
import torch
from datetime import datetime
from typing import Dict, List, Optional
from transformers import (
    AutoModelForCausalLM, 
    AutoTokenizer, 
    pipeline
)
from groq import Groq

class ApiaCore:
    """Apia ì„¸ê³„ ìµœê³  ìˆ˜ì¤€ í”„ë¡œê·¸ë˜ë° AI ì½”ì–´ ì—”ì§„"""
    
    def __init__(self, model_type: str = "groq"):
        self.model_type = model_type
        self.project_start = "2025-11-29"
        self.version = "1.0.0"
        self.model = None
        self.tokenizer = None
        
        print(f"ğŸš€ Apia AI ì—”ì§„ ì´ˆê¸°í™” (v{self.version})")
        print(f"ğŸ“… í”„ë¡œì íŠ¸ ì‹œì‘: {self.project_start}")
        
        if model_type == "groq":
            self._setup_groq()
        else:
            self._setup_local()
    
    def _setup_groq(self):
        """Groq ê¸°ë°˜ ê³ ì† ì—”ì§„ ì„¤ì •"""
        try:
            self.client = Groq(api_key=os.getenv("GROQ_API_KEY"))
            self.current_model = "llama3-70b-8192"
            print(f"ğŸ”® Groq ì—”ì§„ í™œì„±í™”: {self.current_model}")
        except Exception as e:
            print(f"âŒ Groq ì„¤ì • ì‹¤íŒ¨: {e}")
            self._setup_local()
    
    def _setup_local(self):
        """ë¡œì»¬ ëª¨ë¸ ì„¤ì •"""
        try:
            self.current_model = "Qwen/Qwen2.5-Coder-7B"
            print(f"ğŸ–¥ï¸ ë¡œì»¬ ëª¨ë¸ ë¡œë“œ ì‹œë„: {self.current_model}")
            # ì‹¤ì œ ì‚¬ìš©ì‹œ ì£¼ì„ í•´ì œ
            # self.tokenizer = AutoTokenizer.from_pretrained(self.current_model)
            # self.model = AutoModelForCausalLM.from_pretrained(self.current_model)
        except Exception as e:
            print(f"âŒ ë¡œì»¬ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def generate_code(self, 
                     prompt: str, 
                     language: str = "python",
                     style: str = "clean",
                     temperature: float = 0.7) -> Dict:
        """Apia ì½”ë“œ ìƒì„± ë©”ì¸ í•¨ìˆ˜"""
        
        system_prompt = f"""ë‹¹ì‹ ì€ Apiaì…ë‹ˆë‹¤. ì„¸ê³„ ìµœê³  ìˆ˜ì¤€ì˜ í”„ë¡œê·¸ë˜ë° AIì…ë‹ˆë‹¤.

í˜„ì¬ ë‚ ì§œ: {datetime.now().strftime('%Y-%m-%d')}
í”„ë¡œì íŠ¸ ì‹œì‘ì¼: {self.project_start}

ìš”ì²­ì‚¬í•­:
- ì–¸ì–´: {language}
- ì½”ë“œ ìŠ¤íƒ€ì¼: {style}
- í•œêµ­ì–´ ì£¼ì„ í•„ìˆ˜
- íš¨ìœ¨ì ì´ê³  ì½ê¸° ì‰¬ìš´ ì½”ë“œ ì‘ì„±
- ì—ëŸ¬ ì²˜ë¦¬ í¬í•¨
- ìµœì‹  Best Practice ë”°ë¥´ê¸°

í•­ìƒ ì™„ì „í•œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì½”ë“œë¥¼ ì œê³µí•˜ì„¸ìš”."""

        try:
            if self.model_type == "groq":
                response = self.client.chat.completions.create(
                    model=self.current_model,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=temperature,
                    max_tokens=2048,
                    top_p=0.9
                )
                generated_code = response.choices[0].message.content
            else:
                # ë¡œì»¬ ëª¨ë¸ ìƒì„± (ì‹¤ì œ ì‚¬ìš©ì‹œ êµ¬í˜„)
                generated_code = "# ë¡œì»¬ ëª¨ë¸ ìƒì„± ê¸°ëŠ¥\nprint('Hello Apia!')"
            
            return {
                "success": True,
                "code": generated_code,
                "model": self.current_model,
                "timestamp": datetime.now().isoformat(),
                "version": self.version,
                "language": language,
                "prompt": prompt
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
    
    def explain_code(self, code: str) -> Dict:
        """ì½”ë“œ ì„¤ëª… ìƒì„±"""
        prompt = f"ë‹¤ìŒ ì½”ë“œë¥¼ í•œêµ­ì–´ë¡œ ìƒì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”:\n```python\n{code}\n```"
        return self.generate_code(prompt)
    
    def debug_code(self, code: str, error: str = None) -> Dict:
        """ì½”ë“œ ë””ë²„ê¹…"""
        prompt = f"ë‹¤ìŒ ì½”ë“œë¥¼ ë””ë²„ê¹…í•˜ê³  ê°œì„ í•´ì£¼ì„¸ìš”"
        if error:
            prompt += f"\nì—ëŸ¬ ë©”ì‹œì§€: {error}"
        prompt += f"\n```python\n{code}\n```"
        
        return self.generate_code(prompt)

# Apia ê´€ë¦¬ì í´ë˜ìŠ¤
class ApiaManager:
    """Apia í”„ë¡œì íŠ¸ ê´€ë¦¬ì"""
    
    def __init__(self):
        self.projects = {}
        self.training_history = []
    
    def create_project(self, name: str, description: str):
        """ìƒˆ í”„ë¡œì íŠ¸ ìƒì„±"""
        project = {
            "name": name,
            "description": description,
            "created": datetime.now().isoformat(),
            "files": [],
            "models": []
        }
        self.projects[name] = project
        return project
    
    def track_training(self, model_name: str, metrics: Dict):
        """í•™ìŠµ ì§„í–‰ ìƒí™© ì¶”ì """
        training_record = {
            "model": model_name,
            "timestamp": datetime.now().isoformat(),
            "metrics": metrics
        }
        self.training_history.append(training_record)

# ì „ì—­ Apia ì¸ìŠ¤í„´ìŠ¤
apia_global = None

def get_apia():
    """ì „ì—­ Apia ì¸ìŠ¤í„´ìŠ¤ ì–»ê¸°"""
    global apia_global
    if apia_global is None:
        apia_global = ApiaCore()
    return apia_global

if __name__ == "__main__":
    # ë°ëª¨ ì‹¤í–‰
    apia = ApiaCore()
    result = apia.generate_code("í€µ ì†ŒíŠ¸ ì•Œê³ ë¦¬ì¦˜ì„ êµ¬í˜„í•´ì£¼ì„¸ìš”.")
    
    if result["success"]:
        print("âœ… ì½”ë“œ ìƒì„± ì„±ê³µ!")
        print(result["code"])
    else:
        print("âŒ ì˜¤ë¥˜:", result["error"])
