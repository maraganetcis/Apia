import json
import torch
from torch.utils.data import Dataset
from transformers import AutoTokenizer
import random

class CodeDataset(Dataset):
    """ì„¸ê³„ ìµœê³  ìˆ˜ì¤€ ì½”ë“œ ë°ì´í„°ì…‹"""
    
    def __init__(self, jsonl_file, tokenizer, max_length=4096):
        self.tokenizer = tokenizer
        self.max_length = max_length
        self.examples = []
        
        print(f"ğŸ“š ë°ì´í„° ë¡œë”©: {jsonl_file}")
        
        # ëŒ€ê·œëª¨ ë°ì´í„° ë¡œë“œ (50,000+ ìƒ˜í”Œ)
        with open(jsonl_file, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    try:
                        self.examples.append(json.loads(line))
                    except json.JSONDecodeError:
                        continue
        
        # ë°ì´í„° ì¦ê°•
        self.augmented_examples = self._augment_data(self.examples)
        
        print(f"âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ: {len(self.augmented_examples)} ìƒ˜í”Œ")
    
    def _augment_data(self, examples):
        """ë°ì´í„° ì¦ê°• - ì„¸ê³„ ìµœê³  ìˆ˜ì¤€ ë°ì´í„° í’ˆì§ˆ ë³´ì¥"""
        augmented = []
        
        for example in examples:
            # ì›ë³¸ ë°ì´í„°
            augmented.append(example)
            
            # ë³€í˜• 1: ë‹¤ë¥¸ ì–¸ì–´ë¡œ ë³€í™˜ íŒíŠ¸ ì¶”ê°€
            if random.random() < 0.3:
                transformed = example.copy()
                transformed['prompt'] = f"# Convert this to equivalent {random.choice(['JavaScript', 'Java', 'C++', 'Go'])} code:\n{example['prompt']}"
                augmented.append(transformed)
            
            # ë³€í˜• 2: íš¨ìœ¨ì„± ê°œì„  ìš”ì²­
            if random.random() < 0.3:
                optimized = example.copy()
                optimized['prompt'] = f"# Optimize this code for better performance:\n{example['prompt']}"
                augmented.append(optimized)
                
        return augmented
    
    def __len__(self):
        return len(self.augmented_examples)
    
    def __getitem__(self, idx):
        example = self.augmented_examples[idx]
        
        # í”„ë¡¬í”„íŠ¸ì™€ ì™„ì„± ë¶€ë¶„ ê²°í•©
        if 'completion' in example:
            text = f"{example['prompt']}{example['completion']}"
        else:
            text = example['prompt']
        
        # í† í¬ë‚˜ì´ì§•
        encoding = self.tokenizer(
            text,
            max_length=self.max_length,
            padding='max_length',
            truncation=True,
            return_tensors='pt'
        )
        
        return {
            'input_ids': encoding['input_ids'].flatten(),
            'attention_mask': encoding['attention_mask'].flatten(),
            'labels': encoding['input_ids'].flatten()
        }

class MultiTaskCodeDataset(CodeDataset):
    """ë©€í‹°íƒœìŠ¤í¬ í•™ìŠµì„ ìœ„í•œ í–¥ìƒëœ ë°ì´í„°ì…‹"""
    
    def __getitem__(self, idx):
        example = self.augmented_examples[idx]
        
        # íƒœìŠ¤í¬ íƒ€ì…ì— ë”°ë¥¸ í”„ë¡¬í”„íŠ¸ í¬ë§·íŒ…
        task_type = example.get('task_type', 'code_generation')
        
        if task_type == 'bug_fix':
            text = f"ğŸ”§ Fix the bug in this code:\n{example['prompt']}\n\nFixed code:\n{example['completion']}"
        elif task_type == 'code_explain':
            text = f"ğŸ“– Explain this code:\n{example['prompt']}\n\nExplanation:\n{example['completion']}"
        else:  # code_generation
            text = f"ğŸ’» Write code for this task:\n{example['prompt']}\n\nSolution:\n{example['completion']}"
        
        encoding = self.tokenizer(
            text,
            max_length=self.max_length,
            padding='max_length',
            truncation=True,
            return_tensors='pt'
        )
        
        return {
            'input_ids': encoding['input_ids'].flatten(),
            'attention_mask': encoding['attention_mask'].flatten(),
            'labels': encoding['input_ids'].flatten(),
            'task_type': task_type
        }
