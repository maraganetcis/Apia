import torch
import numpy as np
import random
import os
from datetime import datetime
import json
import logging

def setup_world_class_environment(seed=42):
    """ì„¸ê³„ ìµœê³  ìˆ˜ì¤€ ì‹¤í—˜ í™˜ê²½ ì„¤ì •"""
    # ì¬í˜„ì„± ë³´ì¥
    torch.manual_seed(seed)
    np.random.seed(seed)
    random.seed(seed)
    
    # GPU ì„¤ì •
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False
    
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(f'world_class_ai_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'),
            logging.StreamHandler()
        ]
    )
    
    print("ğŸŒ ì„¸ê³„ ìµœê³  ìˆ˜ì¤€ AI í™˜ê²½ ì„¤ì • ì™„ë£Œ!")

def save_world_class_checkpoint(model, tokenizer, epoch, metrics, path):
    """ì„¸ê³„ ìµœê³  ìˆ˜ì¤€ ì²´í¬í¬ì¸íŠ¸ ì €ì¥"""
    checkpoint = {
        'epoch': epoch,
        'model_state_dict': model.state_dict(),
        'metrics': metrics,
        'timestamp': datetime.now().isoformat(),
        'world_class_version': '1.0.0'
    }
    
    # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
    torch.save(checkpoint, f"{path}/checkpoint_epoch_{epoch}.pt")
    
    # ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ì €ì¥
    model.save_pretrained(f"{path}/model_epoch_{epoch}")
    tokenizer.save_pretrained(f"{path}/model_epoch_{epoch}")
    
    # ë©”íƒ€ë°ì´í„° ì €ì¥
    metadata = {
        'epoch': epoch,
        'metrics': metrics,
        'timestamp': datetime.now().isoformat(),
        'model_type': 'WorldClassProgrammingAI'
    }
    
    with open(f"{path}/metadata_epoch_{epoch}.json", 'w') as f:
        json.dump(metadata, f, indent=2)
    
    print(f"ğŸ’¾ ì„¸ê³„ ìµœê³  ìˆ˜ì¤€ ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì™„ë£Œ: ì—í¬í¬ {epoch}")

def load_world_class_checkpoint(model, path, epoch=None):
    """ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ"""
    if epoch is None:
        # ê°€ì¥ ìµœê·¼ ì²´í¬í¬ì¸íŠ¸ ì°¾ê¸°
        checkpoints = [f for f in os.listdir(path) if f.startswith('checkpoint_epoch_')]
        if not checkpoints:
            raise FileNotFoundError("ì²´í¬í¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        latest_checkpoint = max(checkpoints, key=lambda x: int(x.split('_')[-1].split('.')[0]))
        checkpoint_path = f"{path}/{latest_checkpoint}"
    else:
        checkpoint_path = f"{path}/checkpoint_epoch_{epoch}.pt"
    
    checkpoint = torch.load(checkpoint_path)
    model.load_state_dict(checkpoint['model_state_dict'])
    
    print(f"ğŸ“¥ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì™„ë£Œ: {checkpoint_path}")
    return model, checkpoint['metrics']

def calculate_code_quality_score(generated_code, original_code=None):
    """ì½”ë“œ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (ì„¸ê³„ ìµœê³  ìˆ˜ì¤€ í‰ê°€)"""
    score = 0
    
    # 1. ë¬¸ë²• ê²€ì‚¬ (ê¸°ë³¸ ì ìˆ˜)
    try:
        compile(generated_code, '<string>', 'exec')
        score += 30
    except:
        pass
    
    # 2. ì½”ë“œ ê¸¸ì´ íš¨ìœ¨ì„±
    lines = generated_code.split('\n')
    if len(lines) < 50:  # ë„ˆë¬´ ê¸¸ì§€ ì•ŠìŒ
        score += 20
    
    # 3. ì£¼ì„ ì¡´ì¬ ì—¬ë¶€
    if '#' in generated_code or '//' in generated_code or '/*' in generated_code:
        score += 15
    
    # 4. í•¨ìˆ˜ ì •ì˜ ì¡´ì¬ ì—¬ë¶€
    if 'def ' in generated_code or 'function ' in generated_code:
        score += 20
    
    # 5. ì—ëŸ¬ ì²˜ë¦¬ ì¡´ì¬ ì—¬ë¶€
    if 'try:' in generated_code or 'catch' in generated_code or 'except' in generated_code:
        score += 15
    
    return min(score, 100)

class WorldClassMetrics:
    """ì„¸ê³„ ìµœê³  ìˆ˜ì¤€ ë©”íŠ¸ë¦­ ê³„ì‚°"""
    
    @staticmethod
    def calculate_pass_rate(generated_codes, test_cases):
        """ì½”ë“œ í†µê³¼ìœ¨ ê³„ì‚°"""
        passed = 0
        total = len(generated_codes)
        
        for code, test_case in zip(generated_codes, test_cases):
            try:
                # ì‹¤ì œ ì‹¤í–‰ í™˜ê²½ì—ì„œëŠ” ë” ì •êµí•œ í…ŒìŠ¤íŠ¸ í•„ìš”
                exec(code)
                exec(test_case)
                passed += 1
            except:
                continue
        
        return passed / total if total > 0 else 0
    
    @staticmethod
    def calculate_bleu_score(references, candidates):
        """BLEU ìŠ¤ì½”ì–´ ê³„ì‚° (ì½”ë“œ ìœ ì‚¬ë„)"""
        from nltk.translate.bleu_score import sentence_bleu
        
        scores = []
        for ref, cand in zip(references, candidates):
            ref_tokens = ref.split()
            cand_tokens = cand.split()
            
            score = sentence_bleu([ref_tokens], cand_tokens)
            scores.append(score)
        
        return sum(scores) / len(scores) if scores else 0
